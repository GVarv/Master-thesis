---
title: "Compare diameters"
author: "Giulia Varvara"
date: "20/04/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Load pre-processed data:  

```{r Load pre processed data}
load(file="Preprocessing.RData")
```

## Subset to only ID, Species and time unit: 

```{r Create matrix with only information needed for building the network}
europe$level=europe$TIMEUNIT
levels(europe$level)=as.numeric(1:length(levels(europe$TIMEUNIT)))
europe=europe[-which(grepl("( indet.)|( sp.)",europe[,"Genus_Species"])),]
#europe.reduced=europe[,c("LIDNUM","Genus_Species","level")]
if(length(which(grepl("( indet.)|( sp.)",europe[,"Genus_Species"])))!=0){
  europe=europe[-which(grepl("( indet.)|( sp.)",europe[,"Genus_Species"])),]
}
```


```{r}
source("Network_prep.R")
source("Clustering.R")
```


We build the networks for different radius
```{r Create network files}
library(hexbin)
library(splancs)
library(geoscale)
library(alphahull)
library(igraph)
library(topicmodels)
net=c()
i=1
s=sort(c(seq(50,1000,80),500,1000))
for(diam in s){
  net[[i]]=network_prep(europe,diam = diam)
  i=i+1
}
name=paste0("net",s)
names(net)=name
```

Use the file that have been created to make the network in `https://www.mapequation.org/infomap/` using the setting `--clu --tree -s 1-n 50` (the seed and number of repetitions are important to ensure that when we re-run the same analysis with the same file we get the same results).
Then we cluster the so obtained network at the chosen level. For the moment `level_3`seems to be th best since has few NAs but it is still quite specific (the only level without NAs is the first one but it is too generic).


`-s 1 -N 50 multilayer --multilayer-relax-rate 0.25 -f undirected --tree --multilayer-relax-limit 1 --ftree`   Add number to intra

```{r Cluster networks}
net.clu=c()
i=1
for(diam in s){
  unique.eu=net[[i]][["unique.eu"]]
  net.clu[[i]]=clustering(unique.eu ,diam = diam)
  i=i+1
}
name=paste0("clus",s)
names(net.clu)=name
```

```{r}
library(rnaturalearth)
library(ggplot2)
library(sf)
library(gridExtra)
gg=c()
for(i in 1:length(net.clu)){
  # pattern is by finding a set of numbers in the start and capturing them
  diam=as.numeric(gsub("[[:alpha:]]", "",  names(net.clu)[i]))


  sub.sub.eu=net.clu[[i]]$sub.eu
  world <- ne_countries(scale = "medium", returnclass = "sf")
  #Europe <- world[which(world$continent == "Europe"),]
    gg[[i]]=ggplot(world) +
      geom_sf() +
      geom_point(data = sub.sub.eu, mapping = aes(x = LONG, y = LAT,colour=factor(Level_3)),size=2.5) +
    #geom_point(data = adj.frac, mapping = aes(x = LONG, y = LAT), colour = "red",show.legend=FALSE) + 
      coord_sf(xlim = c(-25,45), ylim = c(35,70), expand = FALSE)+
      ggtitle(paste0("Clustering diam ", diam, "km"))+
    
      theme_bw()+
      theme(plot.title = element_text(size = 20, face = "bold",hjust = 0.5),
          panel.background = element_rect(fill = "lightblue",
                                          colour = "lightblue",
                                          size = 0.5, linetype = "solid")
    )

}
```

```{r Plot clusters,fig.width=20,fig.height=10}
library(gridExtra)
#library(cowplot)
library(ggpubr)
library(purrr)
#pp=sapply(net.clu, i="map", function(x,i) x[i])
ggarrange(plotlist = gg,nrow = 2,ncol=2)
```
Now we want to create a table that has the "location" in the rows and the level_3 cluster ID for the different radius.
```{r Create a locationXcluster ID table}
clustering.ids=net.clu[[1]][["cluster.ID"]]
for(i in 2:length(net.clu)){
  clustering.ids=cbind(clustering.ids,net.clu[[i]][["cluster.ID"]][,2])
}
#clustering.ids=as.matrix(clustering.ids)
name=c("LIDNUM",paste0("diam",s))
colnames(clustering.ids)=name
```

Now that we have a data frame with all the cluster IDs for level 3 for each location with the different hexagon radius, we need to find which diversity measure we are going to use in order to measure which clustering radius would be better.  

First we want to see how many cluster there are for each radius at level 3, then we can take the cluster ID for the shortest radius as reference and see how far from that is the cluster ID for different radius.
We can also check how many NAs there are for that radius and maybe repeat the process for lower levels.

```{r Count number of cluster per diameter}
clust.num=apply(clustering.ids,2,function(x) {length(unique(x))})
clust.num
plot(clust.num[2:length(clust.num)], type="b", col="orange",lwd=5,ylab="Number of clusters",xlab="Diameter",xaxt="n")
axis(side=1, at=1:length(s),labels = paste0(s,"km"))
```
We can see that the number of cluster is not monotonically decreasing.  

Now, let's take the radius of 50k as a reference
```{r Difference in cluster ID assignment between different diameters and diam 50km}
clustering.ids=mutate_all(clustering.ids, function(x) as.numeric(as.character(x)))
comparison=cbind(clustering.ids[,"LIDNUM"],apply(clustering.ids[,-1],2, function(x){abs(clustering.ids[,"diam50"]-x)}))
mean.comp=apply(comparison[,-1],2,function(x){mean(x,na.rm = T)})

plot(mean.comp[2:length(mean.comp)], type="b", col="Forest green",lwd=5,ylab="Difference",xlab="Diameter",xaxt="n",main="Cluster ID difference (50km radius as reference)")
axis(side=1, at=1:length(s),labels = paste0(s,"km"))

plot(as.integer(mean.comp[2:length(mean.comp)]), type="b", col="Forest green",lwd=5,ylab="Difference",xlab="Diameter",xaxt="n",main="Cluster ID difference (50km radius as reference)")
axis(side=1, at=1:length(s),labels = paste0(s,"km"))

```
Count number of NAs
```{r Count number of NAs}
num.na=apply(clustering.ids[,-1],2,function(x){length(which(is.na(x)))})
plot(num.na[2:length(mean.comp)], type="b", col="Forest green",lwd=5,ylab="Difference",xlab="Diameter",xaxt="n")
axis(side=1, at=1:length(s),labels = paste0(s,"km"))
plot(num.na[2:length(mean.comp)], type="b", col="Forest green",lwd=5,ylab="Difference",xlab="Diameter",xaxt="n",ylim=c(0,130))
axis(side=1, at=1:length(s),labels = paste0(s,"km"))

plot(num.na[2:length(mean.comp)], type="b", col="Forest green",lwd=5,ylab="Difference",xlab="Diameter",xaxt="n",ylim=c(0,15),yaxt="n")
axis(side=1, at=1:length(s),labels = paste0(s,"km"))
axis(side=2, at=num.na)
```
From the first plot we can see that after 610km the amount of NAs for level 3 are too many.
In the second plot we zoom on smaller number of NAs and we can see they are pretty uniform (just 1 or 2 as a difference, as can be seen by the third plot).  

450km of radius has the lowest number of NAs and the lowest difference in clusters from the 50km radius ones, but it also has less cluster than 500km, which still has a very low number of NAs and of difference from the reference clustering.
So maybe 500km radius is a good enough choice.




1.b.

Count number of NAs per partition per level
```{r}
NA_levels=c()
num.clu=c()
for(i in 1:length(net.clu)){
  ds=net.clu[[i]][["cluster.ID"]]
  num_NA=apply(ds[,-1],2,function(x) sum(is.na(x)))
  NA_levels[[i]]=num_NA
  num.clu[[i]]=apply(ds[,-1],2,function(x) length(unique(x)))
}
names(NA_levels)=names(net.clu)
names(num.clu)=names(net.clu)
```

```{r Calculate number of clusters and NA per level}
NA_levels=c()
num.clu=c()
levels=c("Level_1", "Level_12", "Level_123", "Level_1234" )
for(i in 1:length(net.clu)){
  ds=net.clu[[i]][["cluster.ID"]]
  ds$Level_12=paste(ds$Level_1,ds$Level_2,sep="")
  ds$Level_123=paste(ds$Level_1,ds$Level_2,ds$Level_3,sep="")
  ds$Level_1234=paste(ds$Level_1,ds$Level_2,ds$Level_3,ds$Level_4,sep="")
  #which(apply(ds[,-1], 1, function(x)any(grep("NA",x))),arr.ind=TRUE)
  ds$Level_12[which(grepl("NA",ds$Level_12), arr.ind = TRUE)]=NA
  ds$Level_123[which(grepl("NA",ds$Level_123), arr.ind = TRUE)]=NA
  ds$Level_1234[which(grepl("NA",ds$Level_1234), arr.ind = TRUE)]=NA
  num_NA=apply(ds[,levels],2,function(x) sum(is.na(x)))
  NA_levels[[i]]=num_NA
  num.clu[[i]]=apply(ds[,levels],2,function(x) length(unique(x)))
  net.clu[[i]][["cluster.ID"]]=ds
}
names(NA_levels)=names(net.clu)
names(num.clu)=names(net.clu)
```


```{r}
thr=5
clu.rem=matrix(NA,nrow = length(net.clu),ncol=length(levels),dimnames = list(names(net.clu),levels))
levels=c("Level_1", "Level_12", "Level_123", "Level_1234" )
for(j in levels){
  for(i in 1:length(net.clu)){
    p1=net.clu[[i]]$cluster.ID
    p1l<-tapply(p1[,"LIDNUM"],p1[,j],list)
    knots<- unlist(lapply(p1l,function(x)length(x)))
    sub=which(knots>thr)
    pp1=as.data.frame(p1[which(p1[,j] %in% names(p1l[sub])),])
    pp1l=tapply(pp1[,"LIDNUM"],pp1[,j],list)
    
    clu.rem[i,j]=length(pp1l)
  }
}
```


```{r}
#ln=unlist(lapply(NA_levels, length))
#level=names(NA_levels[[i]])[min(unlist(lapply(NA_levels, length)))]
NAS=c()
n_clu=c()
#levels=paste0("Level_",1:min(unlist(lapply(NA_levels, length))))
for(i in 1:length(NA_levels)){
  NAS=rbind(NAS,NA_levels[[i]][levels])
  
  n_clu=rbind(n_clu,num.clu[[i]][levels])
}
rownames(NAS)=names(net.clu)
rownames(n_clu)=names(net.clu)
```

```{r, fig.height=10, fig.width=20}
par(mfrow=c(1,2))

plot(clu.rem[,1],type="b", col=ncol(clu.rem),lwd=2,xaxt="n", main="Number of clusters per level with more than 5 nodes", ylab="Number of clusters", ylim=c(0, max(clu.rem)))
for(i in (ncol(clu.rem)-1):1){
  lines(clu.rem[,i],col=i,type="b")
}
axis(side=1, at=1:length(s),labels = paste0(s,"km"))
legend("topleft",col=1:ncol(clu.rem),legend=levels,lty=1)

plot(NAS[,ncol(NAS)],type="b", col=ncol(NAS),lwd=2,xaxt="n", ylim=c(0,20000), main="Number of NAs per level", ylab="Number of NAs")
for(i in (ncol(NAS)-1):1){
  lines(NAS[,i],col=i,type="b")
}
axis(side=1, at=1:length(s),labels = paste0(s,"km"))
legend("topleft",col=1:ncol(NAS),legend=levels,lty=1)
```
1.  Remove the small nodes (use a threshold) in the .tree file

```{r Remove cluster with few knots for first 12 layers, fig.width=20}
level="Level_123"
net.rem=c()
for(i in 1:length(net.clu)){
  ds=net.clu[[i]]$sub.eu
    ds$Level_12=paste(ds$Level_1,ds$Level_2,sep="")
    ds$Level_123=paste(ds$Level_1,ds$Level_2,ds$Level_3,sep="")
    ds$Level_1234=paste(ds$Level_1,ds$Level_2,ds$Level_3,ds$Level_4,sep="")
    ds$Level_12[which(grepl("NA",ds$Level_12), arr.ind = TRUE)]=NA
    ds$Level_123[which(grepl("NA",ds$Level_123), arr.ind = TRUE)]=NA
    ds$Level_1234[which(grepl("NA",ds$Level_1234), arr.ind = TRUE)]=NA
    #net.clu[[i]]$sub.eu=ds
     #which.max(table(ds$level))
    ds.not.max=ds[ds$level<12,]
     #which.max(table(ds$level))
  ds.not.max=ds[ds$level<12,]
  p1=ds.not.max
  #print(nrow(p1))
  p1l<-tapply(p1[,"LIDNUM"],p1[,level],list)
  knots<- unlist(lapply(p1l,function(x)length(x)))
  knots
#table(knots)
  thr=5
  #knots[knots<thr]
  sub=which(knots>thr)
  sort(as.numeric(sub))
  #name= c(names(p1l[sub]),"NA")
  name
  #p.rem=p1l[which(knots>thr)]
  pp1=as.data.frame(p1[which(p1[,level] %in% names(p1l[sub])),])
  #nrow(pp1)+length(which(is.na(p1$level_3)))
  pp1l=tapply(pp1[,"LIDNUM"],pp1[,level],list)
  #nrow(pp1)+length(which(is.na(p1$level_3)))+nrow(p1[p1$level_3 %in% names(p1l[-sub]),])

  net.rem[[i]] = list(net.clu=pp1,number_clust_clean=length(pp1l), number_clust_original=length(p1l), number_knots_clean=nrow(pp1),non.na_knots_original=nrow(pp1)+nrow(p1[p1[,level] %in% names(p1l[-sub]),]), number_na=length(which(is.na(p1[,level]))))
  names(net.rem)[i]=names(net.clu)[i]
}

clus_clean=unlist(lapply(net.rem,function(x) x[["number_clust_clean"]]))
clus_or=unlist(lapply(net.rem,function(x) x[["number_clust_original"]]))
s=sort(c(seq(50,1000,80),500,1000))
par(mfrow=c(1,2))
plot(clus_clean,col="Red",lwd=2,type="b",ylab="Number of clusters",xlab="Diameter",xaxt="n", main="Number of clusters for earliest layers",ylim=c(0,max(clus_or)))
lines(clus_or,col="Green",type="b")
axis(side=1, at=1:length(s),labels = paste0(s,"km"))
legend("topright",col=c("Red","Green"),legend=c("Cleand","Full"),lty=1)

plot(clus_or-clus_clean,col="Orange",lwd=2,type="b",ylab="Difference",xlab="Diameter",xaxt="n",main="Difference in number of clusters for the first layers between original and cleaned")
axis(side=1, at=1:length(s),labels = paste0(s,"km"))
#ggplot(aes(y=clus_clean))
```

```{r Remove cluster with few knots for first 12 layers, fig.width=20}
level="Level_123"
net.info=c()
for(i in 1:length(net.clu)){
  ds=net.clu[[i]]$sub.eu
    ds$Level_12=paste(ds$Level_1,ds$Level_2,sep="")
    ds$Level_123=paste(ds$Level_1,ds$Level_2,ds$Level_3,sep="")
    ds$Level_1234=paste(ds$Level_1,ds$Level_2,ds$Level_3,ds$Level_4,sep="")
    ds$Level_12[which(grepl("NA",ds$Level_12), arr.ind = TRUE)]=NA
    ds$Level_123[which(grepl("NA",ds$Level_123), arr.ind = TRUE)]=NA
    ds$Level_1234[which(grepl("NA",ds$Level_1234), arr.ind = TRUE)]=NA

  p1=ds

  #print(nrow(p1))
  p1l<-tapply(p1[,"LIDNUM"],p1[,level],list)
  knots<- unlist(lapply(p1l,function(x)length(x)))
  knots
#table(knots)
  thr=5
  #knots[knots<thr]
  sub=which(knots>thr)

  pp1=as.data.frame(p1[which(p1[,level] %in% names(p1l[sub])),])
  #nrow(pp1)+length(which(is.na(p1$level_3)))
  pp1l=tapply(pp1[,"LIDNUM"],pp1[,level],list)
  #nrow(pp1)+length(which(is.na(p1$level_3)))+nrow(p1[p1$level_3 %in% names(p1l[-sub]),])
  avg=median(unlist(lapply(pp1l, length))) #Choose median because more robust to outliers
  
  net.info[[i]] = list(net.clu=pp1,number_clust_clean=length(pp1l), number_clust_original=length(p1l), number_knots_clean=nrow(pp1),non.na_knots_original=nrow(pp1)+nrow(p1[p1[,level] %in% names(p1l[-sub]),]), number_na=length(which(is.na(p1[,level]))),avg.length_clu=avg)
  names(net.info)[i]=names(net.clu)[i]
}

clus_clean=unlist(lapply(net.info,function(x) x[["number_clust_clean"]]))
clus_or=unlist(lapply(net.info,function(x) x[["number_clust_original"]]))
avg=unlist(lapply(net.info,function(x) x[["avg.length_clu"]]))
s=sort(c(seq(50,1000,80),500,1000))
par(mfrow=c(1,2))
plot(clus_clean,col="Red",lwd=2,type="b",ylab="Number of clusters",xlab="Diameter",xaxt="n", main="Number of clusters",ylim=c(0,max(clus_or)))
lines(clus_or,col="Green",type="b")
axis(side=1, at=1:length(s),labels = paste0(s,"km"))
legend("topright",col=c("Red","Green"),legend=c("Cleand","Full"),lty=1)

plot(avg,col="Dodgerblue",lwd=2,type="b",ylab="Cluster length",xlab="Diameter",xaxt="n",main="Median cluster length")
axis(side=1, at=1:length(s),labels = paste0(s,"km"))
```

```{r Remove cluster with few knots for first 12 layers}
level="Level_123"
net.rem=c()
for(i in 1:length(net.clu)){
  p1=net.clu[[i]]$cluster.ID
  #print(nrow(p1))
  p1l<-tapply(p1[,"LIDNUM"],p1[,level],list)
  knots<- unlist(lapply(p1l,function(x)length(x)))
  knots
#table(knots)
  thr=5
  #knots[knots<thr]
  sub=which(knots>thr)
  sort(as.numeric(sub))
  #name= c(names(p1l[sub]),"NA")
  name
  #p.rem=p1l[which(knots>thr)]
  pp1=as.data.frame(p1[which(p1[,level] %in% names(p1l[sub])),])
  #nrow(pp1)+length(which(is.na(p1$level_3)))
  pp1l=tapply(pp1[,"LIDNUM"],pp1[,level],list)
  #nrow(pp1)+length(which(is.na(p1$level_3)))+nrow(p1[p1$level_3 %in% names(p1l[-sub]),])

  net.rem[[i]] = list(net.clu=pp1,number_clust_clean=length(pp1l), number_clust_original=length(p1l), number_knots_clean=nrow(pp1),non.na_knots_original=nrow(pp1)+nrow(p1[p1[,level] %in% names(p1l[-sub]),]), number_na=length(which(is.na(p1[,level]))))
  names(net.rem)[i]=names(net.clu)[i]
}

clus_clean=unlist(lapply(net.rem,function(x) x[["number_clust_clean"]]))
clus_or=unlist(lapply(net.rem,function(x) x[["number_clust_original"]]))
s=sort(c(seq(50,1000,80),500,1000))
par(mfrow=c(1,2))
plot(clus_clean,col="Red",lwd=2,type="b",ylab="Number of clusters",xlab="Diameter",xaxt="n", main="Number of clusters",ylim=c(0,max(clus_or)))
lines(clus_or,col="Green",type="b")
axis(side=1, at=1:length(s),labels = paste0(s,"km"))
legend("topright",col=c("Red","Green"),legend=c("Cleand","Full"),lty=1)

plot(clus_or-clus_clean,col="Orange",lwd=2,type="b",ylab="Difference",xlab="Diameter",xaxt="n",main="Difference in number of clusters between original and cleaned")
axis(side=1, at=1:length(s),labels = paste0(s,"km"))
#ggplot(aes(y=clus_clean))
```

2.  Write the number of knots

```{r,fig.width=15, fig.height=10}
clean_knots=unlist(lapply(net.rem,function(x) x[["number_knots_clean"]]))
original_knots=unlist(lapply(net.rem,function(x) x[["non.na_knots_original"]]))
num_na=unlist(lapply(net.rem,function(x) x[["number_na"]]))


plot(clean_knots,col="Red",lwd=2,type="b",ylab="Number of knots",xlab="Diameter",xaxt="n",main="Number of non NA knots in clusters")
lines(original_knots,col="Green",type="b")
axis(side=1, at=1:length(s),labels = paste0(s,"km"))
legend("topright",col=c("Red","Green"),legend=c("Cleand","Full"), lty = 1)

par(mfrow=c(1,2))
plot(original_knots-clean_knots,col="Dodgerblue",lwd=2,type="b",ylab="Difference in number of knots",xlab="Diameter",xaxt="n",main="Difference in number of knots between full and cleaned clusterings")
axis(side=1, at=1:length(s),labels = paste0(s,"km"))
plot(num_na,col="Orange",lwd=2,type="b",ylab="Number of NAs",xlab="Diameter",xaxt="n",main="Number of NAs for partition")
axis(side=1, at=1:length(s),labels = paste0(s,"km"))

```
Codelength=Description length in bit (how much bit of info the random walker needs to describe this partition)
Plot number of level (look at net.tree in clustering.R)->More complexity=more levels, when lose level lose structure


3.  Calculate number of : Cluster, grid cells, levels (depth of hierarchy) per solution

```{r Level of hierarchy per partition}
for(i in 1:length(net.clu)){
  p1=net.clu[[i]]$cluster.ID
  levels[i]=length(which(grepl("Level",colnames(p1))))
}
names(levels)=names(net.clu)
plot(levels,col="Blue",lwd=2,type="b",ylab="Number of levels",xlab="Diameter",xaxt="n",main="Number of levels for partition", ylim=c(0,7))
axis(side=1, at=1:length(s),labels = paste0(s,"km"))
```
```{r}
#unique.eu$tID identifies the grid cell in space and time so we can use it to count the number of grid cells per partition
tID=c()
for(i in 1:length(net)){
  eu=net[[i]][["unique.eu"]]
  tID[i]=length(unique(eu$tID))
}
names(tID)=names(net)
plot(tID,col=950,lwd=2,type="b",ylab="Number of grid cells",xlab="Diameter",xaxt="n",main="Number of grid cells for partition")
axis(side=1, at=1:length(s),labels = paste0(s,"km"))
```


4.  Calculate Jacard similarity


To calculate the jacard dissimilarity we first have to remove the Nas ,otherwise the function will not give the right results.

```{r Jacard similarity function}
#p1=net.clu[[j]]$cluster.ID
#p2=net.clu[[i]]$cluster.ID
#level="Level_3"

jacard_similarty <- function(p1,p2, level){ 
  p1=p1[!is.na(p1[,level]),]
  p2=p2[!is.na(p2[,level]),]
	p1l<-tapply(p1[,1],p1[,2],list) #List if clusters and what locations are inside them
	p2l<-tapply(p2[,1],p2[,2],list) 
	cp1<-c() 
	for(i in 1:length(p1l)){ 
		com <- unlist(lapply(p2l,function(x)sum(unique(x)%in%unique(p1l[[i]])))) #For every cluster in the second list find how many elements in the ith cluster of the first list
		tot <- unlist(lapply(p2l,function(x)length(unique(c(x,p1l[[i]]))))) #Unique location in the combines group of the "selected" cluster in the second list and the ith cluster in the first one
		#len <- length(p1l[[i]])/nrow(p1) 
		len <- length(unique(p1l[[i]]))/length(unique(p1$LIDNUM)) #element in the ith cluster of the first list divided by the total number of unique locations in the dataset
		cp1[i]<-max(com/tot)*len
		} 
	cp2<-c() 
	for(i in 1:length(p2l)){ 
		com <- unlist(lapply(p1l,function(x)sum(unique(x)%in%unique(p2l[[i]])))) 
		tot <- unlist(lapply(p1l,function(x)length(unique(c(x,p2l[[i]]))))) 
		#len <- length(p2l[[i]])/nrow(p2) 
		len<- length(unique(p2l[[i]]))/length(unique(p2$LIDNUM))
		cp2[i]<-max(com/tot)*len 
		}
	p1_to_p2 <- sum(cp1) 
	p2_to_p1 <- sum(cp2) 
	jacmul <- mean(c(p1_to_p2,p2_to_p1) ) 
	return(cbind(p1_to_p2=p1_to_p2,p2_tp_p1=p2_to_p1,jacmul=jacmul)) 
} 
```


```{r Jacard similarity and heatmap, fig.width=7, fig.height=7}

jacard=matrix(NA,nrow = length(net.clu),ncol=length(net.clu),dimnames = list(names(net.clu),names(net.clu)))
for(i in 1:length(net.clu)){
  for(j in 1:length(net.clu)){
    ds_j=net.clu[[j]]$sub.eu[net.clu[[j]]$sub.eu$level %in% 1:11,] #For the other layers do level 4
    ds_i=net.clu[[i]]$sub.eu[net.clu[[i]]$sub.eu$level %in% 1:11,]
    #which(ds$level==1)
    
    #Remove all NAs
    ds_j=ds_j[!is.na(ds_j$Level_3),]
    ds_i=ds_i[!is.na(ds_i$Level_3),]
    
    #ds=ds[-which(is.na(ds[,c("Level_1","Level_2","Level_3")])),]
    ds_j$Level_123=paste(ds_j$Level_1,ds_j$Level_2,ds_j$Level_3, sep="")
    ds_i$Level_123=paste(ds_i$Level_1,ds_i$Level_2,ds_i$Level_3, sep="")
    #jac=jacard_similarty(net.clu[[j]]$cluster.ID,net.clu[[i]]$cluster.ID, level = "Level_123" )  #combine level 1, 2 and 3
    jac=jacard_similarty(ds_j,ds_i, level = "Level_123" )
    print(jac[,"jacmul"])
    jacard[i,j]=jac[,"jacmul"]
    
    
  }
}
#heatmap(jacard,Rowv=NA,Colv = "Rowv", scale="row")
heatmap(jacard,Rowv=NA,Colv = "Rowv", scale="none")
#gplots::heatmap.2(jacard,,Colv=FALSE,dendrogram="none",scale="row")
```
```{r}
save.image(file = "p.rand.RData")
```

5.  Perplexity

Perplexity is also called number of effective modules. First calculate the Shannon entropy of the partition. Then, perplexity would be 2 ^-(Entropy). 
From the tree file, create an object with module sizes

```{r Find levels that are present in all the partitions}
levels=lapply(net.clu, function (x) colnames(x$cluster.ID))
commonCols <- Reduce(intersect,levels)
levels=commonCols[which(grepl("Level",commonCols))]
#levels[which(grepl("( indet.)|( sp.)",levels))]
```


```{r Entropy function}

Perplexity=matrix(NA,nrow = length(net.clu),ncol=length(levels),dimnames = list(names(net.clu),levels))

for(l in levels){
  level=l
  for(i in 1:length(net.clu)){
    modules=data.frame(table(net.clu[[i]]$cluster.ID[,level]))

    m <- nrow(modules)# number of modules
    n <- sum(modules$Freq)  # number of nodes

    Hx <- NULL
    for(j in 1:m){
      nx <- modules$Freq[j]
      H <- (nx/n)*log2(nx/n)
      Hx <- rbind(Hx, H)
    }
    
    Entropy <- sum(Hx)

#Then Calculate number of effective modules,

    Perplexity[i,l] <- 2^(-(Entropy))
  }
}
#rownames(Perplexity)=names(net.clu)
#colnames(Perplexity)=levels
```

```{r fig.width=10}
labs=c("Level 1","Level 2","Level 3","Level 4")
plot(Perplexity[,1],col=1,lwd=2,type="b",ylab="Perplexity",xlab="Diameter",xaxt="n",main="Perplexity", ylim=c(0,max(Perplexity)))
axis(side=1, at=1:length(s),labels = paste0(s,"km"))
for(i in 2:ncol(Perplexity)){
  lines(Perplexity[,i],col=i, type = "b")
}
legend("topleft", col = 1:ncol(Perplexity),legend = labs, lty=1)

par(mfrow=c(1,2))
plot(Perplexity[,3],col=3,lwd=2,type="b",ylab="Perplexity",xlab="Diameter",xaxt="n",main="Perplexity", ylim=c(0,10))
axis(side=1, at=1:length(s),labels = paste0(s,"km"))

plot(clus_clean,col="Red",lwd=2,type="b",ylab="Number of clusters",xlab="Diameter",xaxt="n", main="Number of clusters", ylim=c(0,45))
lines(clus_or,col="Green",type="b")
axis(side=1, at=1:length(s),labels = paste0(s,"km"))
legend("topright",col=c("Red","Green"),legend=c("Cleand","Full"),lty=1)
```
Explore this plot but using only one layer.
Subset to only first cluster of level 1 and plot again




```{r Perplexity only for layer with most data}
Perplexity_max.layer=matrix(NA,nrow = length(net.clu),ncol=length(levels),dimnames = list(names(net.clu),levels))

for(l in levels){
  level=l
  for(i in 1:length(net.clu)){
    ds=net.clu[[i]]$sub.eu
    ds$Level_12=paste(ds$Level_1,ds$Level_2,sep="")
    ds$Level_123=paste(ds$Level_1,ds$Level_2,ds$Level_3,sep="")
    ds$Level_1234=paste(ds$Level_1,ds$Level_2,ds$Level_3,ds$Level_4,sep="")
    ds$Level_12[which(grepl("NA",ds$Level_12), arr.ind = TRUE)]=NA
    ds$Level_123[which(grepl("NA",ds$Level_123), arr.ind = TRUE)]=NA
    ds$Level_1234[which(grepl("NA",ds$Level_1234), arr.ind = TRUE)]=NA
    net.clu[[i]]$sub.eu=ds
     #which.max(table(ds$level))
    ds.not.max=ds[ds$level<12,]
    modules=data.frame(table(ds.not.max[,level]))
    if(nrow(modules)==0){
      Perplexity_max.layer[i,l]=0
    }else{
      m <- nrow(modules)# number of modules
    n <- sum(modules$Freq)  # number of nodes

    Hx <- NULL
    for(j in 1:m){
      nx <- modules$Freq[j]
      H <- (nx/n)*log2(nx/n)
      Hx <- rbind(Hx, H)
    }
    
    Entropy <- sum(Hx)

#Then Calculate number of effective modules,

    Perplexity_max.layer[i,l] <- 2^(-(Entropy))
    
    }

    
  }
}

plot(Perplexity_max.layer[,1],col=1,lwd=2,type="b",ylab="Perplexity",xlab="Diameter",xaxt="n",main="Perplexity for lower layers",ylim=c(0,max(Perplexity_max.layer)))
axis(side=1, at=1:length(s),labels = paste0(s,"km"))
for(i in 2:ncol(Perplexity_max.layer)){
  lines(Perplexity_max.layer[,i],col=i, type = "b")
}
legend("topleft", col = 1:ncol(Perplexity_max.layer),legend = labs, lty=1)

```



```{r}
Perplexity=matrix(NA,nrow = length(net.clu),ncol=length(levels),dimnames = list(names(net.clu),levels))

for(l in levels){
  level=l
  for(i in 1:length(net.clu)){
    
    modules=data.frame(table(net.clu[[i]]$cluster.ID[net.clu[[i]]$cluster.ID[,"Level_1"]==2,level]))

    m <- nrow(modules)# number of modules
    n <- sum(modules$Freq)  # number of nodes

    Hx <- NULL
    for(j in 1:m){
      nx <- modules$Freq[j]
      H <- (nx/n)*log2(nx/n)
      Hx <- rbind(Hx, H)
    }
    
    Entropy <- sum(Hx)

#Then Calculate number of effective modules,

    Perplexity[i,l] <- 2^(-(Entropy))
  }
}

plot(Perplexity[,1],col=1,lwd=2,type="b",ylab="Perplexity",xlab="Diameter",xaxt="n",main="Perplexity", ylim=c(0,10))
axis(side=1, at=1:length(s),labels = paste0(s,"km"))
for(i in 2:ncol(Perplexity)){
  lines(Perplexity[,i],col=i, type = "b")
}
legend("topleft", col = 1:ncol(Perplexity),legend = levels, lty=1)
```

```{r}
level2=net.clu[["370"]]$sub.eu[net.clu[["370"]]$sub.eu[,"Level_1"]==1,"Level_2"]


level1=net.clu[[4]]$sub.eu[net.clu[[4]]$sub.eu["Level_1"]==1,c("level","Level_1")]
plot(level1$level, level1$Level_1)
```
```{r}
level1=net.clu[[4]]$sub.eu[net.clu[[4]]$sub.eu["Level_1"]==2,c("level","Level_1")]
plot(level1$level, level1$Level_1)
```
```{r}
level1=net.clu[["clus500"]]$sub.eu[net.clu[["clus500"]]$sub.eu["Level_1"]==1,c("level","Level_1")]
plot(level1$level, level1$Level_1)
```
We can conclude that level 1 is temproal structure
```{r}
#table(pp1$Level_1)
level1=net.clu[["clus500"]]$sub.eu[net.clu[["clus500"]]$sub.eu$Level_1 %in% sub,c("LIDNUM","level","Level_1", "Level_2", "Level_3", "Level_4","Level_5")]
sub=which(table(level1$Level_1)>5)
level1=level1[level1$Level_1 %in% sub,]
#sub

plot(level1$level, level1$Level_1,pch=as.numeric(level1$Level_1), col=level1$Level_1,xlab="Time unit",ylab="Cluster ID",xaxt="n",main="Cluster ID vs layers, Level 1")
axis(side=1, at=1:length(lab),labels = lab)
#legend("topright", col =unique(level1$Level_1),legend = level1$Level_1, lty=1)
```

```{r}
level2=level1[level1$Level_1==1,c("level","Level_2")]
sub=which(table(level2$Level_2)>5)
level2=level2[level2$Level_2 %in% sub,]

plot(level2$level, level2$Level_2,pch=as.numeric(level2$Level_2), col=level2$Level_2,xlab="Time unit",ylab="Cluster ID",xaxt="n",main="Cluster ID vs layers, Level 2")
axis(side=1, at=1:length(lab),labels = lab)
```
Also here no geograpahical info
```{r}
level_23=level1[level1$Level_1==1,]
level_23$Level_23=paste(level_23$Level_2,level_23$Level_3,sep="")
sub=which(table(level_23$Level_23)>5)
level_23=level_23[level_23$Level_23 %in% sub,]

plot(level_23$level, level_23$Level_23, col=level_23$Level_23,xlab="Time unit",ylab="Cluster ID",xaxt="n",main="Cluster ID vs layers, Level 3")
axis(side=1, at=1:length(lab),labels = lab)
```


```{r}
ds=net.clu[[7]]$sub.eu
ds$level_234=paste(net.clu[[7]]$sub.eu$Level_2,net.clu[[7]]$sub.eu$Level_3,net.clu[[7]]$sub.eu$Level_4, sep="")
ds=ds[,c("level","level_234")]
#level3=net.clu[[4]]$sub.eu[net.clu[[4]]$sub.eu[,"Level_1"]==1,c("level","Level_2", "Level_3")]
plot(ds$level, ds$level_234)
```
